{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-01T20:27:30.940030Z",
     "start_time": "2025-01-01T20:27:29.903450Z"
    }
   },
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "\n",
    "model = (AutoModelForCausalLM.from_pretrained\n",
    "    (\n",
    "    \"microsoft/Phi-3.5-mini-instruct\", \n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    #attn_implementation = 'eager'\n",
    "    )\n",
    ")\n",
    "\n",
    "rag_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    #attn_implementation = 'eager'\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac6da4928bb64fbfb633c99dc0229eb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T20:27:38.144350Z",
     "start_time": "2025-01-01T20:27:36.038629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "\n",
    "db_path=\"./vektor_DB\"\n",
    "\n",
    "#lädt datenbank lokal runter\n",
    "client = chromadb.PersistentClient(path=db_path)\n",
    "\n",
    "#unser emdedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/gtr-t5-large\")\n",
    "\n",
    "#\"meinungen\" aus der Datenbank laden\n",
    "collection = client.get_collection(\"meinungen\")\n",
    "\n",
    "#retrievet daten von unserer Vektorendatenbank\n",
    "def query_collection(query_text, n_results=4):\n",
    "\n",
    "    #encode query text (-> unser input)\n",
    "    query_embedding = embedding_model.encode(query_text)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    return results"
   ],
   "id": "6cbf98147c913d55",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T21:38:33.554949Z",
     "start_time": "2025-01-01T20:27:47.505944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Funktion, die die Datenbank abfragt und eine Antwort generiert\n",
    "def query_with_phi3_5(query_text):\n",
    "    results = query_collection(query_text)\n",
    "    context = \"\"\n",
    "    for i in range(len(results[\"documents\"][0])):\n",
    "        context += f\"Document {i+1}:\\n\"\n",
    "        context += f\"{results['documents'][0][i]}\\n\"\n",
    "        context += f\"Party: {results['metadatas'][0][i]['party']}\\n\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a political AI assistant.  Based on the following information retrieved from a vector database, answer the user's question.  If the provided data is not relevant to the question, respond with \"I do not know\".\n",
    "\n",
    "    User Question: {query_text}\n",
    "\n",
    "    Retrieved Data:\n",
    "    {context}\n",
    "\n",
    "    Your Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    generated_text = rag_pipeline(prompt, max_new_tokens=250)[0][\"generated_text\"]\n",
    "    # Extract the answer from the generated text (remove the prompt)\n",
    "    answer = generated_text[len(prompt):].strip()\n",
    "    return answer\n",
    "\n",
    "\n",
    "query = \"Was denkt die AFD über Islamunterricht an deutschen Schulen?\"\n",
    "answer = query_with_phi3_5(query)\n",
    "print(answer)"
   ],
   "id": "872eced4560dec8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die AfD sieht den Islamunterricht an deutschen Schulen kritisch und befürwortet eine sachliche Islamkunde im Ethikunterricht. Sie befürchten, dass der Islamunterricht echte Integration verhindern könnte, da islamische Gemeinschaften keine kirchenähnliche Struktur aufweisen und daher kein „bekenntnisgebundener“ Religionsunterricht zugestanden werden kann. Die Partei fordert, dass Imame und Lehrer*innen in deutscher Sprache und mit einem Zertifikat B2 für die deutsche Sprache des Gemeinsamen Europäischen Referenzrahmens für Sprachen zugelassen werden. Zudem lehnt die AfD die Verleihung des Status als Körperschaft öffentlichen Rechts an islamische Organisationen ab und fordert die Abschaffung der islamtheologischen Lehrstühle an deutschen Universitäten. Sie unterstützt zudem die Gleichberechtigung von Mann und Frau und fordert die Untersagung des Tragens von Burka und Niqab in der Öffentlichkeit.\n",
      "\n",
      "\n",
      "Document:\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d1bbea06127b45f7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
