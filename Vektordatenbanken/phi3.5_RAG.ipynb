{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-01T20:27:30.940030Z",
     "start_time": "2025-01-01T20:27:29.903450Z"
    }
   },
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3.5-mini-instruct\")\n",
    "\n",
    "model = (AutoModelForCausalLM.from_pretrained\n",
    "    (\n",
    "    \"microsoft/Phi-3.5-mini-instruct\", \n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    #attn_implementation = 'eager'\n",
    "    )\n",
    ")\n",
    "\n",
    "rag_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    #attn_implementation = 'eager'\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac6da4928bb64fbfb633c99dc0229eb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T20:27:38.144350Z",
     "start_time": "2025-01-01T20:27:36.038629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "\n",
    "\n",
    "db_path=\"./vektor_DB\"\n",
    "\n",
    "#lädt datenbank lokal runter\n",
    "client = chromadb.PersistentClient(path=db_path)\n",
    "\n",
    "#unser emdedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/gtr-t5-large\")\n",
    "\n",
    "#\"meinungen\" aus der Datenbank laden\n",
    "collection = client.get_collection(\"meinungen\")\n",
    "\n",
    "#retrievet daten von unserer Vektorendatenbank\n",
    "def query_collection(query_text, n_results=4):\n",
    "\n",
    "    #encode query text (-> unser input)\n",
    "    query_embedding = embedding_model.encode(query_text)\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results,\n",
    "        include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "    )\n",
    "    return results"
   ],
   "id": "6cbf98147c913d55",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T21:38:33.554949Z",
     "start_time": "2025-01-01T20:27:47.505944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Funktion, die die Datenbank abfragt und eine Antwort generiert\n",
    "def query_with_phi3_5(query_text):\n",
    "    results = query_collection(query_text)\n",
    "    context = \"\"\n",
    "    for i in range(len(results[\"documents\"][0])):\n",
    "        context += f\"Document {i+1}:\\n\"\n",
    "        context += f\"{results['documents'][0][i]}\\n\"\n",
    "        context += f\"Party: {results['metadatas'][0][i]['party']}\\n\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a political AI assistant.  Based on the following information retrieved from a vector database, answer the user's question.  If the provided data is not relevant to the question, respond with \"I do not know\".\n",
    "\n",
    "    User Question: {query_text}\n",
    "\n",
    "    Retrieved Data:\n",
    "    {context}\n",
    "\n",
    "    Your Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    generated_text = rag_pipeline(prompt, max_new_tokens=250)[0][\"generated_text\"]\n",
    "    # Extract the answer from the generated text (remove the prompt)\n",
    "    answer = generated_text[len(prompt):].strip()\n",
    "    return answer\n",
    "\n",
    "\n",
    "query = \"Was denkt die AFD über Islamunterricht an deutschen Schulen?\"\n",
    "answer = query_with_phi3_5(query)\n",
    "print(answer)"
   ],
   "id": "872eced4560dec8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die AfD sieht den Islamunterricht an deutschen Schulen kritisch und befürwortet eine sachliche Islamkunde im Ethikunterricht. Sie befürchten, dass der Islamunterricht echte Integration verhindern könnte, da islamische Gemeinschaften keine kirchenähnliche Struktur aufweisen und daher kein „bekenntnisgebundener“ Religionsunterricht zugestanden werden kann. Die Partei fordert, dass Imame und Lehrer*innen in deutscher Sprache und mit einem Zertifikat B2 für die deutsche Sprache des Gemeinsamen Europäischen Referenzrahmens für Sprachen zugelassen werden. Zudem lehnt die AfD die Verleihung des Status als Körperschaft öffentlichen Rechts an islamische Organisationen ab und fordert die Abschaffung der islamtheologischen Lehrstühle an deutschen Universitäten. Sie unterstützt zudem die Gleichberechtigung von Mann und Frau und fordert die Untersagung des Tragens von Burka und Niqab in der Öffentlichkeit.\n",
      "\n",
      "\n",
      "Document:\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:28:24.684941Z",
     "start_time": "2025-01-13T16:28:24.678069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# Funktion zur Berechnung der ROUGE-Metrik\n",
    "def evaluate_rouge(predictions, references):\n",
    "    # Definiere die zu berechnenden ROUGE-Metriken\n",
    "    rouge_types = [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "    \n",
    "    # Initialisiere den scorer mit den gewünschten Metriken\n",
    "    scorer = rouge_scorer.RougeScorer(rouge_types=rouge_types)\n",
    "    \n",
    "    scores = {\"rouge1\": [], \"rouge2\": [], \"rougeL\": []}\n",
    "    \n",
    "    for pred, ref in zip(predictions, references):\n",
    "        score = scorer.score(ref, pred)\n",
    "        scores[\"rouge1\"].append(score[\"rouge1\"].fmeasure)\n",
    "        scores[\"rouge2\"].append(score[\"rouge2\"].fmeasure)\n",
    "        scores[\"rougeL\"].append(score[\"rougeL\"].fmeasure)\n",
    "\n",
    "    # Durchschnittliche F1-Score für jede ROUGE-Metrik berechnen\n",
    "    avg_scores = {metric: sum(scores[metric])/len(scores[metric]) for metric in scores}\n",
    "    return avg_scores\n",
    "\n",
    "# Beispiel für eine generierte Antwort und eine Referenzantwort\n",
    "generated_answer = \"Die AFD ist kritisch gegenüber dem Islamunterricht in deutschen Schulen.\"\n",
    "reference_answer = \"Die AFD lehnt den Islamunterricht an deutschen Schulen ab und betrachtet ihn als problematisch.\"\n",
    "\n",
    "# Aufruf der Evaluierungsfunktion\n",
    "average_scores = evaluate_rouge([generated_answer], [reference_answer])\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "print(\"Durchschnittliche ROUGE-Scores:\")\n",
    "for metric, score in average_scores.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n"
   ],
   "id": "d1bbea06127b45f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchschnittliche ROUGE-Scores:\n",
      "rouge1: 0.4000\n",
      "rouge2: 0.1739\n",
      "rougeL: 0.4000\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:30:15.166707Z",
     "start_time": "2025-01-13T16:30:15.151291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "y_true = [1]  # Wahre Label (z.B. Ja=1, Nein=0)\n",
    "y_pred = [1]  # Vorhergesagte Label\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ],
   "id": "dc1da34ad752c658",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "F1 Score: 1.0000\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T16:34:29.518306Z",
     "start_time": "2025-01-13T16:34:28.165705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "\n",
    "# Lade ein NER-Modell\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "reference = \"Die AFD lehnt den Islamunterricht an deutschen Schulen ab.\"\n",
    "candidate = \"Die AFD ist kritisch gegenüber dem Islamunterricht in deutschen Schulen.\"\n",
    "\n",
    "reference_doc = nlp(reference)\n",
    "candidate_doc = nlp(candidate)\n",
    "\n",
    "reference_entities = set(ent.text for ent in reference_doc.ents)\n",
    "candidate_entities = set(ent.text for ent in candidate_doc.ents)\n",
    "\n",
    "print(\"Reference Entities:\", reference_entities)\n",
    "print(\"Candidate Entities:\", candidate_entities)\n",
    "print(\"Matching Entities:\", reference_entities & candidate_entities)\n"
   ],
   "id": "ab139f6dbc56a84d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference Entities: {'AFD', 'deutschen'}\n",
      "Candidate Entities: {'AFD', 'deutschen'}\n",
      "Matching Entities: {'AFD', 'deutschen'}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:02:17.324314Z",
     "start_time": "2025-01-14T10:02:13.409306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Lade das deutsche Spacy-Modell\n",
    "try:\n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "except OSError:\n",
    "    import subprocess\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"de_core_news_sm\"])\n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "# Embedding-Modell für semantische Ähnlichkeit\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/gtr-t5-large\")\n",
    "\n",
    "# Referenz- und Kandidatenantworten\n",
    "reference = \"Die AFD lehnt den Islamunterricht an deutschen Schulen ab und betrachtet ihn als problematisch.\"\n",
    "candidate = \"Die AFD ist kritisch gegenüber dem Islamunterricht in deutschen Schulen.\"\n",
    "\n",
    "# Funktion: Berechne semantische Ähnlichkeit\n",
    "def calculate_semantic_similarity(reference, candidate):\n",
    "    ref_embedding = embedding_model.encode(reference, convert_to_tensor=True)\n",
    "    cand_embedding = embedding_model.encode(candidate, convert_to_tensor=True)\n",
    "    similarity = util.cos_sim(ref_embedding, cand_embedding).item()\n",
    "    return similarity\n",
    "\n",
    "# Funktion: Entitäten extrahieren\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    return {ent.text for ent in doc.ents}\n",
    "\n",
    "# Berechnung der Metriken\n",
    "def evaluate_model(reference, candidate):\n",
    "    # Debugging: Originaltexte anzeigen\n",
    "    print(f\"Reference: {reference}\")\n",
    "    print(f\"Candidate: {candidate}\")\n",
    "\n",
    "    # 1. Accuracy (basierend auf exakter Übereinstimmung)\n",
    "    accuracy = 1.0 if reference == candidate else 0.0\n",
    "    print(f\"Accuracy (exact match): {accuracy}\")\n",
    "\n",
    "    # 2. Semantische Ähnlichkeit\n",
    "    semantic_similarity = calculate_semantic_similarity(reference, candidate)\n",
    "    print(f\"Semantic Similarity: {semantic_similarity:.4f}\")\n",
    "\n",
    "    # 3. Precision, Recall, F1-Score (basierend auf Entitäten)\n",
    "    ref_entities = extract_entities(reference)\n",
    "    cand_entities = extract_entities(candidate)\n",
    "\n",
    "    # Debugging: Extrahierte Entitäten anzeigen\n",
    "    print(f\"Reference Entities: {ref_entities}\")\n",
    "    print(f\"Candidate Entities: {cand_entities}\")\n",
    "\n",
    "    true_positive = len(ref_entities & cand_entities)\n",
    "    false_positive = len(cand_entities - ref_entities)\n",
    "    false_negative = len(ref_entities - cand_entities)\n",
    "\n",
    "    # Debugging: TP, FP, FN anzeigen\n",
    "    print(f\"True Positives: {true_positive}\")\n",
    "    print(f\"False Positives: {false_positive}\")\n",
    "    print(f\"False Negatives: {false_negative}\")\n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0.0\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0.0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Average Semantic Similarity\": semantic_similarity,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1\n",
    "    }\n",
    "\n",
    "# Evaluation durchführen\n",
    "results = evaluate_model(reference, candidate)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "for metric, score in results.items():\n",
    "    print(f\"{metric}: {score:.4f}\")\n"
   ],
   "id": "6f308a56320bde31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: Die AFD lehnt den Islamunterricht an deutschen Schulen ab und betrachtet ihn als problematisch.\n",
      "Candidate: Die AFD ist kritisch gegenüber dem Islamunterricht in deutschen Schulen.\n",
      "Accuracy (exact match): 0.0\n",
      "Semantic Similarity: 0.9409\n",
      "Reference Entities: {'AFD', 'deutschen'}\n",
      "Candidate Entities: {'AFD', 'deutschen'}\n",
      "True Positives: 2\n",
      "False Positives: 0\n",
      "False Negatives: 0\n",
      "Accuracy: 0.0000\n",
      "Average Semantic Similarity: 0.9409\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7053b8407487bd9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
